{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import depthai\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closer-in minimum depth, disparity range is doubled (from 95 to 190):\n",
    "extended_disparity = False\n",
    "# Better accuracy for longer distance, fractional disparity 32-levels:\n",
    "subpixel = False\n",
    "# Better handling for occlusions:\n",
    "lr_check = True\n",
    "\n",
    "#create pipeline for the RGB color camera\n",
    "pipeline = depthai.Pipeline()\n",
    "rgb = pipeline.create(depthai.node.ColorCamera)\n",
    "rgb.setPreviewSize(640,480)\n",
    "rgb.setInterleaved(False)\n",
    "\n",
    "#create pipeline for the right mono camera\n",
    "right = pipeline.create(depthai.node.MonoCamera)\n",
    "right.setBoardSocket(depthai.CameraBoardSocket.RIGHT)\n",
    "right.setResolution(depthai.MonoCameraProperties.SensorResolution.THE_480_P)\n",
    "\n",
    "#create pipeline for the left mono camera\n",
    "left = pipeline.create(depthai.node.MonoCamera)\n",
    "left.setBoardSocket(depthai.CameraBoardSocket.LEFT)\n",
    "left.setResolution(depthai.MonoCameraProperties.SensorResolution.THE_480_P)\n",
    "\n",
    "#create pipeline for the stereo depth camera using the left and right cameras\n",
    "depth = pipeline.create(depthai.node.StereoDepth)\n",
    "xout = pipeline.create(depthai.node.XLinkOut)\n",
    "xout_rgb = pipeline.create(depthai.node.XLinkOut)\n",
    "\n",
    "#set the stream names for both RGB and stereo depth cameras in order for them to be used in the pipeline for display\n",
    "xout_rgb.setStreamName(\"rgb\")\n",
    "xout.setStreamName(\"disparity\")\n",
    "\n",
    "# Create a node that will produce the depth map (using disparity output as it's easier to visualize depth this way)\n",
    "depth.setDefaultProfilePreset(depthai.node.StereoDepth.PresetMode.HIGH_DENSITY)\n",
    "# Options: MEDIAN_OFF, KERNEL_3x3, KERNEL_5x5, KERNEL_7x7 (default)\n",
    "depth.initialConfig.setMedianFilter(depthai.MedianFilter.KERNEL_7x7)\n",
    "depth.setLeftRightCheck(lr_check)\n",
    "depth.setExtendedDisparity(extended_disparity)\n",
    "depth.setSubpixel(subpixel)\n",
    "\n",
    "# Linking all of the camera nodes together for use in the pipeline\n",
    "rgb.preview.link(xout_rgb.input)\n",
    "left.out.link(depth.left)\n",
    "right.out.link(depth.right)\n",
    "depth.disparity.link(xout.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Communication exception - possible device error/misconfiguration. Original message 'Couldn't read data from stream: 'disparity' (X_LINK_ERROR)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m fps_captures \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[0;32m     11\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     \u001b[39m#get the stereo cameras frames\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     inDisparity \u001b[39m=\u001b[39m q_depth\u001b[39m.\u001b[39;49mget()\n\u001b[0;32m     14\u001b[0m     frame \u001b[39m=\u001b[39m inDisparity\u001b[39m.\u001b[39mgetFrame()\n\u001b[0;32m     15\u001b[0m     \u001b[39m# Normalization for better visualization\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Communication exception - possible device error/misconfiguration. Original message 'Couldn't read data from stream: 'disparity' (X_LINK_ERROR)'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#gather the frame rates seen by the camera while running both\n",
    "pre_f_time = 0\n",
    "new_f_time = 0\n",
    "\n",
    "with depthai.Device(pipeline) as device:\n",
    "    # Output queue will be used to get the depth and rgb frames from the outputs defined above\n",
    "    q_depth = device.getOutputQueue(name=\"disparity\", maxSize=1, blocking=False)\n",
    "    q_rgb = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "    #create a list to store the fps captures as they happen\n",
    "    fps_captures = list()\n",
    "    while True:\n",
    "        #get the stereo cameras frames\n",
    "        inDisparity = q_depth.get()\n",
    "        frame = inDisparity.getFrame()\n",
    "        # Normalization for better visualization\n",
    "        frame = (frame * (255 / depth.initialConfig.getMaxDisparity())).astype(np.uint8)\n",
    "        frame = cv2.applyColorMap(frame, cv2.COLORMAP_JET)\n",
    "        cv2.imshow(\"disparity_color\", frame)\n",
    "        #get the rgb camera frames\n",
    "        in_rgb = q_rgb.tryGet()\n",
    "\n",
    "        #add the fps to the RGB camera so it can be seen as the frames change per second\n",
    "        if in_rgb is not None:\n",
    "            frame = in_rgb.getCvFrame()\n",
    "            new_f_time = time.time()\n",
    "            fps = 1/(new_f_time-pre_f_time)\n",
    "            fps_captures.append(fps)\n",
    "            pre_f_time = new_f_time\n",
    "            fps = str(int(fps))\n",
    "            cv2.putText(frame, fps, (7, 70), cv2.FONT_HERSHEY_SIMPLEX, 3, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "            cv2.imshow(\"rgb\", frame)\n",
    "        #exit code to kill the program\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg fps:  40\n",
      "median fps:  26\n"
     ]
    }
   ],
   "source": [
    "#display the average and the median fps experienced by the camera during the run\n",
    "np_fps = np.array(fps_captures)\n",
    "np_fps.sort()\n",
    "print(\"average fps: \",int(np_fps.mean()))\n",
    "print(\"median fps: \",int(np_fps[int(len(np_fps)/2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "308159fa9b6c6619a1f26cdc1093eb362191d23a9b1739232d13ec31d5a998e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
